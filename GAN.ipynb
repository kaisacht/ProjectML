{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = pd.read_csv('dataset_capec_combine.csv')\n",
    "data_source = data_source[data_source['label']=='242 - Code Injection']\n",
    "data_target  = pd.read_csv('dataset_capec_transfer.csv')\n",
    "data_target = data_target[data_target['label']=='242 - Code Injection']\n",
    "X_source = data_source['text'].str.replace('/',' ')\n",
    "y_source = data_source['label']\n",
    "X_target  = data_target ['text'].str.replace('/','')\n",
    "y_target  = data_target ['label']\n",
    "rlist =['000 - Normal', '126 - Path Traversal',\n",
    "       '153 - Input Data Manipulation', '194 - Fake the Source of Data',\n",
    "       '242 - Code Injection', '310 - Scanning for Vulnerable Software',\n",
    "       '34 - HTTP Response Splitting']\n",
    "mapping = {l: i+1 for i, l in enumerate(rlist)}\n",
    "y_source = [mapping[s] for s in y_source] \n",
    "y_target  = [mapping[r] for r in y_target ]\n",
    "y_source = np.array(y_source)\n",
    "y_target  = np.array(y_target )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text                                                                                                    label       \n",
       "GET /blog/index.php/comments/feed/                                                                      000 - Normal    14245\n",
       "GET /blog/index.php/2020/04/04/ipsa-ea-porro-distinctio/                                                000 - Normal     4367\n",
       "GET /blog/index.php/2020/04/04/hic-porro-nihil-non-rerum/                                               000 - Normal     4243\n",
       "GET /blog/index.php/feed/                                                                               000 - Normal     4132\n",
       "GET /blog/index.php/2020/04/04/explicabo-qui-fuga-distinctio-dolores-voluptatibus-sit/                  000 - Normal     3249\n",
       "                                                                                                                        ...  \n",
       "GET /blog/index.php/2020/etc%2Fpasswd/29/distinctio-sequi-officiis-occaecati/embed                      000 - Normal        1\n",
       "GET /blog/index.php/2020/etc%2Fpasswd/29/distinctio-sequi-officiis-occaecati/feed                       000 - Normal        1\n",
       "GET /blog/index.php/2020/etc%2Fpasswd/page/2                                                            000 - Normal        1\n",
       "GET /blog/index.php/2020/http%3A%2F%2F8501779237819759495.owasp.org/04/animi-sint-ut-sed-commodi/embed  000 - Normal        1\n",
       "GET /blog/index.php/tag%22+%2F+sleep%2815%29+%2F+%22/hic-quod-et-odit/feed                              000 - Normal        1\n",
       "Length: 90954, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_source)\n",
    "X_source = tokenizer.texts_to_sequences(X_source)\n",
    "X_source = pad_sequences(X_source, maxlen=40)\n",
    "\n",
    "tokenizer.fit_on_texts(X_target )\n",
    "X_target = tokenizer.texts_to_sequences(X_target )\n",
    "X_target = pad_sequences(X_target , maxlen=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226509, 40)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_source.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"\"\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(40, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), 40)\n",
    "        output = self.model(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator().to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(40, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 40),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        output = output.view(x.size(0), 40)\n",
    "        return output\n",
    "\n",
    "generator = Generator().to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.00001\n",
    "num_epochs = 1000\n",
    "batch_size=64\n",
    "loss_function = nn.BCELoss()\n",
    "\n",
    "optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
    "optimizer_generator = torch.optim.Adam(generator.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_tensor(tensor):\n",
    "    # Tính giá trị trung bình và độ lệch chuẩn của tensor\n",
    "    tensor = tensor.float()\n",
    "    mean = tensor.mean()\n",
    "    std = tensor.std()\n",
    "\n",
    "    # Chuẩn hóa Z-score\n",
    "    normalized_tensor = (tensor - mean) / std\n",
    "\n",
    "    return normalized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_source = torch.from_numpy(X_source).to(device=device)\n",
    "X_source = normalize_tensor(X_source)\n",
    "X_target = torch.from_numpy(X_target).to(device=device)\n",
    "X_target = normalize_tensor(X_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100 Loss D.: 0.6965636610984802\n",
      "Epoch: 100 Loss G.: 0.6972460150718689\n",
      "Epoch: 200 Loss D.: 0.6272693872451782\n",
      "Epoch: 200 Loss G.: 0.6768917441368103\n",
      "Epoch: 300 Loss D.: 0.6509124636650085\n",
      "Epoch: 300 Loss G.: 0.5995656847953796\n",
      "Epoch: 400 Loss D.: 0.617836058139801\n",
      "Epoch: 400 Loss G.: 0.7476617693901062\n",
      "Epoch: 500 Loss D.: 0.5930208563804626\n",
      "Epoch: 500 Loss G.: 0.7631440758705139\n",
      "Epoch: 600 Loss D.: 0.5204918384552002\n",
      "Epoch: 600 Loss G.: 0.7584710121154785\n",
      "Epoch: 700 Loss D.: 0.48490265011787415\n",
      "Epoch: 700 Loss G.: 0.8943015933036804\n",
      "Epoch: 800 Loss D.: 0.4583350718021393\n",
      "Epoch: 800 Loss G.: 1.0644950866699219\n",
      "Epoch: 900 Loss D.: 0.5489089488983154\n",
      "Epoch: 900 Loss G.: 1.0157688856124878\n",
      "Epoch: 1000 Loss D.: 0.4010257124900818\n",
      "Epoch: 1000 Loss G.: 1.2658493518829346\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    idx = np.random.randint(0, X_source.shape[0], batch_size)\n",
    "    real_samples  = X_source[idx]\n",
    "    real_samples_labels = torch.ones((batch_size,1)).to(device=device)\n",
    "    latent_space_samples = torch.rand((batch_size,40)).to( device=device)\n",
    "    \n",
    "    generated_samples = generator(latent_space_samples)\n",
    "    generated_samples_labels = torch.zeros((batch_size, 1)).to(\n",
    "            device=device\n",
    "        )\n",
    "    all_samples = torch.cat((real_samples, generated_samples))\n",
    "    all_samples_labels = torch.cat(\n",
    "            (real_samples_labels, generated_samples_labels)\n",
    "        )\n",
    "\n",
    "        # Training the discriminator\n",
    "    discriminator.zero_grad()\n",
    "    output_discriminator = discriminator(all_samples)\n",
    "    loss_discriminator = loss_function(\n",
    "            output_discriminator, all_samples_labels\n",
    "        )\n",
    "    loss_discriminator.backward()\n",
    "    optimizer_discriminator.step()\n",
    "\n",
    "        # Data for training the generator\n",
    "    latent_space_samples = torch.rand((batch_size,40)).to(device=device)\n",
    "\n",
    "        # Training the generator\n",
    "    generator.zero_grad()\n",
    "    generated_samples = generator(latent_space_samples)\n",
    "    output_discriminator_generated = discriminator(generated_samples)\n",
    "    loss_generator = loss_function(\n",
    "            output_discriminator_generated, real_samples_labels\n",
    "        )\n",
    "    loss_generator.backward()\n",
    "    optimizer_generator.step()\n",
    "    if(epoch%100==0):\n",
    "        print(f\"Epoch: {epoch+100} Loss D.: {loss_discriminator}\")\n",
    "        print(f\"Epoch: {epoch+100} Loss G.: {loss_generator}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = int (X_source.shape[0]*0.2/64)\n",
    "for i in range(k):\n",
    "    latent_space_samples = torch.rand((batch_size,40)).to(device=device)\n",
    "    X_source = torch.cat([X_source, generator(latent_space_samples)], dim=0)\n",
    "torch.save(X_source, 'tensor_000.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 40])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(latent_space_samples).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([271757, 40])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_source.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_elements_greater_than(tensor, threshold):\n",
    "    # Áp dụng phép so sánh >= threshold\n",
    "    mask = tensor >= threshold\n",
    "\n",
    "    # Tính tổng các phần tử True trong mask\n",
    "    count = torch.sum(mask)\n",
    "\n",
    "    return count.item()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], size=(0, 40))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m predicted_labels \u001b[39m=\u001b[39m discriminator(X_target)\n\u001b[0;32m      3\u001b[0m cou \u001b[39m=\u001b[39m count_elements_greater_than(predicted_labels, \u001b[39m0.5\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m cou\u001b[39m/\u001b[39;49mpredicted_labels\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m]\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "predicted_labels = discriminator(X_target)\n",
    "\n",
    "cou = count_elements_greater_than(predicted_labels, 0.5)\n",
    "\n",
    "cou/predicted_labels.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
